{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis\n",
    "- PCA reduces the dimensionality of data from higher to lower.\n",
    "- In theory there is no increase in model performance after PCA but in practice the performance of model may increase.\n",
    "\n",
    "Source\n",
    "- https://plot.ly/ipython-notebooks/principal-component-analysis/\n",
    "- https://www.coursera.org/lecture/machine-learning/choosing-the-number-of-principal-components-S1bq1\n",
    "- https://stats.stackexchange.com/questions/55034/how-does-pca-improve-the-accuracy-of-a-predictive-model\n",
    "- https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the random X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9, 15, 64],\n",
       "       [28, 89, 93],\n",
       "       [29,  8, 73],\n",
       "       [ 0, 40, 36],\n",
       "       [16, 11, 54],\n",
       "       [88, 62, 33],\n",
       "       [72, 78, 49],\n",
       "       [51, 54, 77],\n",
       "       [69, 13, 25],\n",
       "       [13, 92, 86]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "X = np.random.randint(100, size=(10,3))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean of X across column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37.5, 46.2, 59. ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean = np.mean(X, axis=0)\n",
    "X_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation of X across column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.91107054, 31.72317765, 22.17205448])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_var = np.std(X, axis=0)\n",
    "X_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.98578155, -0.98350803,  0.2255091 ],\n",
       "       [-0.32859385,  1.34917127,  1.53346186],\n",
       "       [-0.29400502, -1.20416688,  0.63142547],\n",
       "       [-1.29708099, -0.1954407 , -1.03734185],\n",
       "       [-0.74365977, -1.1095988 , -0.2255091 ],\n",
       "       [ 1.74673573,  0.49805855, -1.17264731],\n",
       "       [ 1.19331451,  1.00242165, -0.4510182 ],\n",
       "       [ 0.46694916,  0.24587701,  0.81183275],\n",
       "       [ 1.08954803, -1.04655342, -1.53346186],\n",
       "       [-0.84742625,  1.44373935,  1.21774913]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = (X - X_mean) / X_var\n",
    "X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance Matrix of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.17761524, -0.43087725],\n",
       "       [ 0.17761524,  1.        ,  0.40661502],\n",
       "       [-0.43087725,  0.40661502,  1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cov = np.matmul(X_std.T,X_std)/(X_std.shape[0])\n",
    "X_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigen Value and Eigen Vector of Covariance Matrix of X\n",
    "\n",
    "Eigen vector gives the direction of component and eigen value gives about the variance of data in that direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen Values:\n",
      " [0.31222915 1.17725232 1.51051853] \n",
      "\n",
      "Eigen Vectors: \n",
      " [[ 0.54483383 -0.68156765 -0.48848914]\n",
      " [-0.52653672 -0.73144979  0.43329008]\n",
      " [ 0.65262178 -0.02113638  0.75738898]]\n"
     ]
    }
   ],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(X_cov)\n",
    "print(\"Eigen Values:\\n\",eig_vals,\"\\n\")\n",
    "print(\"Eigen Vectors: \\n\",eig_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3122291500261839, array([ 0.54483383, -0.52653672,  0.65262178])),\n",
       " (1.1772523178708882, array([-0.68156765, -0.73144979, -0.02113638])),\n",
       " (1.5105185321029295, array([-0.48848914,  0.43329008,  0.75738898]))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "eig_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.5105185321029295, array([-0.48848914,  0.43329008,  0.75738898])),\n",
       " (1.1772523178708882, array([-0.68156765, -0.73144979, -0.02113638])),\n",
       " (0.3122291500261839, array([ 0.54483383, -0.52653672,  0.65262178]))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "eig_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection Matrix\n",
    "Projection Matrix is constructed from the top two principle components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.48848914, -0.68156765],\n",
       "       [ 0.43329008, -0.73144979],\n",
       "       [ 0.75738898, -0.02113638]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_matrix = np.hstack((eig_pairs[0][1].reshape(3,1),\n",
    "                      eig_pairs[1][1].reshape(3,1)))\n",
    "p_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New 2D X_std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22619741,  1.38649711],\n",
       "       [ 1.90652417, -0.79530393],\n",
       "       [ 0.10009939,  1.06782588],\n",
       "       [-0.23674382,  1.04892915],\n",
       "       [-0.28830654,  1.3232367 ],\n",
       "       [-1.52560775, -1.53003788],\n",
       "       [-0.49017803, -1.53701278],\n",
       "       [ 0.49330966, -0.51526333],\n",
       "       [-2.14712071,  0.05531241],\n",
       "       [ 1.96182623, -0.50418333]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std_dim = np.matmul(X_std, p_matrix)\n",
    "X_std_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_Std Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05548656, -0.91614392,  0.1420139 ],\n",
       "       [-0.38926292,  1.4078029 ,  1.46079024],\n",
       "       [-0.77669304, -0.73768894,  0.0532442 ],\n",
       "       [-0.59926939, -0.86981775, -0.20147772],\n",
       "       [-0.76104071, -1.09280156, -0.24632863],\n",
       "       [ 1.78806714,  0.45811517, -1.12313904],\n",
       "       [ 1.28702483,  0.91185839, -0.33876856],\n",
       "       [ 0.11021041,  0.59063543,  0.3845181 ],\n",
       "       [ 1.011146  , -0.97078436, -1.62737467],\n",
       "       [-0.61469576,  1.21882463,  1.49652217]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std_approx = np.matmul(X_std_dim, p_matrix.T)\n",
    "X_std_approx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss in information after applying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 10.41%\n"
     ]
    }
   ],
   "source": [
    "num = np.sum((X_std - X_std_approx)**2)\n",
    "den = np.sum((X_std)**2)\n",
    "loss = num*100 / den\n",
    "print(\"Loss : {0:.2f}%\".format(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
